{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5cd7ebbc-f2c8-4d36-ba08-d54e62f3b8a7",
   "metadata": {},
   "source": [
    "# Part 3: Deep Learning Model with Transformers\n",
    "## Author: Brady Lamson\n",
    "## Date: Fall 2023\n",
    "# Overview and Motivation\n",
    "\n",
    "This portion of the project has a couple distinct goals. \n",
    "\n",
    "Firstly, I shall utilize the `distilibert-base-uncased` model to attempt to predict the primary and secondary types of pokemon entirely from their text descriptions.\n",
    "\n",
    "Secondly, this notebook will function as a detailed walkthrough to fine tuning a huggingface transformer. Much of the information for this task is scattered throughout documentation and articles of varying levels of utility, so compiling all of that information into one notebook will result in something that will hopefully be useful to me and anyone who may read this. \n",
    "\n",
    "This walkthrough will also utilize hyperparameter search using the `optuna` library, which many articles I have read online seem to lack. I hope this will give this walkthrough a useful niche that other guides have not filled.\n",
    "\n",
    "## References\n",
    "\n",
    "As I've never done multi-label classification using `transformers` before I'll be using [this guide by Ronak Patel](https://colab.research.google.com/github/rap12391/transformers_multilabel_toxic/blob/master/toxic_multilabel.ipynb#scrollTo=CQQ7CoOag_r7) that is featured in [towardsdatascience](https://towardsdatascience.com/transformers-for-multilabel-classification-71a1a0daf5e1). I won't be following it 1:1 but it's there to help me get some traction.\n",
    "\n",
    "## Potential Limitations\n",
    "\n",
    "Performance of this model will be sought after but is not the end goal. I fear that the dataset I am working with will put a cap on performance. Pokemon types are extremely varied, with 19 types existing in this dataset alone. On top of that, I am predicting on both primary and secondary types which turns this into a multi-label prediction problem. Thus, combinations of types become important and many combinations of types only appear once. This is a limitation that likely cannot be overcome without removing problematic rows from the training split or simply acquiring more data. \n",
    "\n",
    "A future improvement that is outside the scope of this project is to collect all of the pokemon descriptions from each game. There are many pokemon games, and using this would allow us to duplicate many pokemon and artifically make certain type combinations more frequent and inflate our dataset. This would also provide more descriptions to train on as they tend to be similar but not identical in every game. This is obviously not without its downsides as it would inflate the frequency of already frequent type combinations, but a variant of this plan with a bit more thought put into it may be worth considering if maximizing model performance is a priority."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33ebd30e-c3ea-4c89-aaa5-38cddea9675d",
   "metadata": {},
   "source": [
    "# Data Loading and Preprocessing\n",
    "\n",
    "Our goal here is to do the same pre-processing as in part 2. So we'll have a bit of a repeat of that content.\n",
    "From there we'll need to convert our dataset to the transformers `DatasetDict` which will contain all of our splits. The big difference here is taking our same dataframe and doing what we need to do to it to get it working within the transforers framework."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c52aaa0e-5e4d-4d19-ba46-9ae133281996",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# Set seed\n",
    "np.random.seed(776)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4379d62f-b519-4ce1-8343-a8c70dfdcc8b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>english_name</th>\n",
       "      <th>primary_type</th>\n",
       "      <th>secondary_type</th>\n",
       "      <th>description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Bulbasaur</td>\n",
       "      <td>grass</td>\n",
       "      <td>poison</td>\n",
       "      <td>There is a plant seed on its back right from t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ivysaur</td>\n",
       "      <td>grass</td>\n",
       "      <td>poison</td>\n",
       "      <td>When the bulb on its back grows large, it appe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Venusaur</td>\n",
       "      <td>grass</td>\n",
       "      <td>poison</td>\n",
       "      <td>Its plant blooms when it is absorbing solar en...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Charmander</td>\n",
       "      <td>fire</td>\n",
       "      <td>none</td>\n",
       "      <td>It has a preference for hot things. When it ra...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Charmeleon</td>\n",
       "      <td>fire</td>\n",
       "      <td>none</td>\n",
       "      <td>It has a barbaric nature. In battle, it whips ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  english_name primary_type secondary_type  \\\n",
       "0    Bulbasaur        grass         poison   \n",
       "1      Ivysaur        grass         poison   \n",
       "2     Venusaur        grass         poison   \n",
       "3   Charmander         fire           none   \n",
       "4   Charmeleon         fire           none   \n",
       "\n",
       "                                         description  \n",
       "0  There is a plant seed on its back right from t...  \n",
       "1  When the bulb on its back grows large, it appe...  \n",
       "2  Its plant blooms when it is absorbing solar en...  \n",
       "3  It has a preference for hot things. When it ra...  \n",
       "4  It has a barbaric nature. In battle, it whips ...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 898 entries, 0 to 897\n",
      "Data columns (total 4 columns):\n",
      " #   Column          Non-Null Count  Dtype   \n",
      "---  ------          --------------  -----   \n",
      " 0   english_name    898 non-null    object  \n",
      " 1   primary_type    898 non-null    category\n",
      " 2   secondary_type  898 non-null    category\n",
      " 3   description     898 non-null    object  \n",
      "dtypes: category(2), object(2)\n",
      "memory usage: 17.3+ KB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "None"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>english_name</th>\n",
       "      <th>primary_type</th>\n",
       "      <th>secondary_type</th>\n",
       "      <th>description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>898</td>\n",
       "      <td>898</td>\n",
       "      <td>898</td>\n",
       "      <td>898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>898</td>\n",
       "      <td>18</td>\n",
       "      <td>19</td>\n",
       "      <td>896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>Bulbasaur</td>\n",
       "      <td>water</td>\n",
       "      <td>none</td>\n",
       "      <td>Although it’s alien to this world and a danger...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>1</td>\n",
       "      <td>123</td>\n",
       "      <td>429</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       english_name primary_type secondary_type  \\\n",
       "count           898          898            898   \n",
       "unique          898           18             19   \n",
       "top       Bulbasaur        water           none   \n",
       "freq              1          123            429   \n",
       "\n",
       "                                              description  \n",
       "count                                                 898  \n",
       "unique                                                896  \n",
       "top     Although it’s alien to this world and a danger...  \n",
       "freq                                                    3  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data_path = \"./data/pokemon.csv\"\n",
    "data_exists = os.path.isfile(data_path)\n",
    "\n",
    "if not data_exists:\n",
    "    # This part requires a kaggle api key. On linux this will be saved to your home directory in .kaggle/kaggle.json\n",
    "    !kaggle datasets download -d cristobalmitchell/pokedex\n",
    "    !unzip pokedex.zip -d data\n",
    "\n",
    "df = (\n",
    "    # load in the data\n",
    "    pd.read_csv(data_path, sep='\\t', encoding='utf-16-le')\n",
    "    # select the relevant columns\n",
    "    .loc[:, ['english_name', 'primary_type', 'secondary_type', 'description']]\n",
    "    # Change the type columns into categories and handle NaNs in secondary typing\n",
    "    .assign(\n",
    "        primary_type=lambda x: x['primary_type'].astype(\"category\"),\n",
    "        secondary_type=lambda x: x['secondary_type'].fillna(\"none\").astype(\"category\")\n",
    "    )\n",
    ")\n",
    "display(df.head())\n",
    "display(df.info())\n",
    "display(df.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdf9c68b-7ffd-4ede-8386-9fd7e0d70d01",
   "metadata": {},
   "source": [
    "## Vectorize Categorical Data\n",
    "\n",
    "Here we'll do the same one-hot encoding as in part 2. Here we'll do it before the splits though as, in retrospect, doing this after the split made no sense. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ec216d7a-5085-42c2-810d-c5fef30c68cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>english_name</th>\n",
       "      <th>primary_type</th>\n",
       "      <th>secondary_type</th>\n",
       "      <th>description</th>\n",
       "      <th>cleaned_text</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Bulbasaur</td>\n",
       "      <td>grass</td>\n",
       "      <td>poison</td>\n",
       "      <td>There is a plant seed on its back right from t...</td>\n",
       "      <td>plant seed back right day pokémon born seed sl...</td>\n",
       "      <td>[1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ivysaur</td>\n",
       "      <td>grass</td>\n",
       "      <td>poison</td>\n",
       "      <td>When the bulb on its back grows large, it appe...</td>\n",
       "      <td>bulb back grows large appears lose ability sta...</td>\n",
       "      <td>[1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Venusaur</td>\n",
       "      <td>grass</td>\n",
       "      <td>poison</td>\n",
       "      <td>Its plant blooms when it is absorbing solar en...</td>\n",
       "      <td>plant blooms absorbing solar energy stays move...</td>\n",
       "      <td>[1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Charmander</td>\n",
       "      <td>fire</td>\n",
       "      <td>none</td>\n",
       "      <td>It has a preference for hot things. When it ra...</td>\n",
       "      <td>preference hot things rains steam said spout t...</td>\n",
       "      <td>[0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Charmeleon</td>\n",
       "      <td>fire</td>\n",
       "      <td>none</td>\n",
       "      <td>It has a barbaric nature. In battle, it whips ...</td>\n",
       "      <td>barbaric nature battle whips fiery tail around...</td>\n",
       "      <td>[0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>893</th>\n",
       "      <td>Regieleki</td>\n",
       "      <td>electric</td>\n",
       "      <td>none</td>\n",
       "      <td>This Pokémon is a cluster of electrical energy...</td>\n",
       "      <td>pokémon cluster electrical energy said removin...</td>\n",
       "      <td>[0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>894</th>\n",
       "      <td>Regidrago</td>\n",
       "      <td>dragon</td>\n",
       "      <td>none</td>\n",
       "      <td>An academic theory proposes that Regidrago’s a...</td>\n",
       "      <td>academic theory proposes regidrago arms head a...</td>\n",
       "      <td>[0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>895</th>\n",
       "      <td>Glastrier</td>\n",
       "      <td>ice</td>\n",
       "      <td>none</td>\n",
       "      <td>Glastrier emits intense cold from its hooves. ...</td>\n",
       "      <td>glastrier emits intense cold hooves also belli...</td>\n",
       "      <td>[0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>896</th>\n",
       "      <td>Spectrier</td>\n",
       "      <td>ghost</td>\n",
       "      <td>none</td>\n",
       "      <td>It probes its surroundings with all its senses...</td>\n",
       "      <td>probes surroundings senses save one use sense ...</td>\n",
       "      <td>[0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>897</th>\n",
       "      <td>Calyrex</td>\n",
       "      <td>psychic</td>\n",
       "      <td>grass</td>\n",
       "      <td>Calyrex is a merciful Pokémon, capable of prov...</td>\n",
       "      <td>calyrex merciful pokémon capable providing hea...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>898 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    english_name primary_type secondary_type  \\\n",
       "0      Bulbasaur        grass         poison   \n",
       "1        Ivysaur        grass         poison   \n",
       "2       Venusaur        grass         poison   \n",
       "3     Charmander         fire           none   \n",
       "4     Charmeleon         fire           none   \n",
       "..           ...          ...            ...   \n",
       "893    Regieleki     electric           none   \n",
       "894    Regidrago       dragon           none   \n",
       "895    Glastrier          ice           none   \n",
       "896    Spectrier        ghost           none   \n",
       "897      Calyrex      psychic          grass   \n",
       "\n",
       "                                           description  \\\n",
       "0    There is a plant seed on its back right from t...   \n",
       "1    When the bulb on its back grows large, it appe...   \n",
       "2    Its plant blooms when it is absorbing solar en...   \n",
       "3    It has a preference for hot things. When it ra...   \n",
       "4    It has a barbaric nature. In battle, it whips ...   \n",
       "..                                                 ...   \n",
       "893  This Pokémon is a cluster of electrical energy...   \n",
       "894  An academic theory proposes that Regidrago’s a...   \n",
       "895  Glastrier emits intense cold from its hooves. ...   \n",
       "896  It probes its surroundings with all its senses...   \n",
       "897  Calyrex is a merciful Pokémon, capable of prov...   \n",
       "\n",
       "                                          cleaned_text  \\\n",
       "0    plant seed back right day pokémon born seed sl...   \n",
       "1    bulb back grows large appears lose ability sta...   \n",
       "2    plant blooms absorbing solar energy stays move...   \n",
       "3    preference hot things rains steam said spout t...   \n",
       "4    barbaric nature battle whips fiery tail around...   \n",
       "..                                                 ...   \n",
       "893  pokémon cluster electrical energy said removin...   \n",
       "894  academic theory proposes regidrago arms head a...   \n",
       "895  glastrier emits intense cold hooves also belli...   \n",
       "896  probes surroundings senses save one use sense ...   \n",
       "897  calyrex merciful pokémon capable providing hea...   \n",
       "\n",
       "                                                labels  \n",
       "0    [1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, ...  \n",
       "1    [1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, ...  \n",
       "2    [1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, ...  \n",
       "3    [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, ...  \n",
       "4    [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, ...  \n",
       "..                                                 ...  \n",
       "893  [0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "894  [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "895  [0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "896  [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "897  [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, ...  \n",
       "\n",
       "[898 rows x 6 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "names = list(df.secondary_type.unique())\n",
    "id2label = {i: label for i, label in enumerate(names)}\n",
    "label2id = {label: i for i, label in enumerate(names)}\n",
    "\n",
    "def map_types(row):\n",
    "    type_encoding = [0] * len(names)\n",
    "    primary_id = label2id[row['primary_type']]\n",
    "    secondary_id = label2id[row['secondary_type']]\n",
    "\n",
    "    type_encoding[primary_id] = 1\n",
    "    type_encoding[secondary_id] = 1\n",
    "    \n",
    "    # return [primary_id, secondary_id]\n",
    "    return type_encoding\n",
    "\n",
    "df['labels'] = df.apply(lambda row: map_types(row), axis=1)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "37635fd7-62cf-4b23-a7b9-d0bd576d8a37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "grass\n",
      "poison\n",
      "[1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "print(df.iloc[0][\"primary_type\"])\n",
    "print(df.iloc[0][\"secondary_type\"])\n",
    "print(df.iloc[0][\"labels\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56a80a81-5857-4217-a3a2-1dda7d634141",
   "metadata": {},
   "source": [
    "## Sanity Check: Verify our Preprocessing and Mapping Worked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a0e7b7ce-072f-4f1f-b5e9-5a5c990947ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actual: grass, poison\n",
      "Mapped: poison, grass\n",
      "\n",
      "Actual: grass, poison\n",
      "Mapped: poison, grass\n",
      "\n",
      "Actual: grass, poison\n",
      "Mapped: poison, grass\n",
      "\n",
      "Actual: fire, none\n",
      "Mapped: none, fire\n",
      "\n",
      "Actual: fire, none\n",
      "Mapped: none, fire\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for index, row in df.head().iterrows():\n",
    "    actual_primary = row[\"primary_type\"]\n",
    "    actual_secondary = row[\"secondary_type\"]\n",
    "    mapped_types = [i for i, x in enumerate(row[\"labels\"]) if x == 1]\n",
    "    mapped_primary = id2label[mapped_types[0]]\n",
    "    mapped_secondary = id2label[mapped_types[1]]\n",
    "\n",
    "    print(f\"Actual: {actual_primary}, {actual_secondary}\")\n",
    "    print(f\"Mapped: {mapped_primary}, {mapped_secondary}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15b8afd8-bc90-4ee4-84db-9def570fd444",
   "metadata": {},
   "source": [
    "## Split The Dataset and Create DatasetDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5924e5a0-6070-4428-b80a-c0c70bb96f03",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# This provides a 70/15/15 split\n",
    "train, test = train_test_split(df, test_size=0.3, random_state=10)\n",
    "test, val = train_test_split(test, test_size=0.5, random_state=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5154fbf1-dd54-4fb3-bb16-1d4c3dd348a4",
   "metadata": {},
   "source": [
    "Now what we want to do is convert this into a format transformers can work with, the `Dataset` object. It's just another way of storing data is all, nothing scary. We use their `Dataset.from_pandas()` method to easily convert and provide some additional information. Really the only important part here is specifying that the labels are a \"Sequence\" of \"ClassLabels\". Or, in laymens terms, a list of class ids.\n",
    "\n",
    "Then we just use a larger container `DatasetDict` to easily store all 3 of our splits. So we don't have to juggle 5000 million different objects. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d971ef5c-f38a-49cc-965f-339603e2f8d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import (\n",
    "    Dataset, DatasetDict, Features,\n",
    "    ClassLabel, Value, Sequence\n",
    ")\n",
    "from transformers import AutoTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6e3d19ba-bc0b-46be-94c5-9f91896e47f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataset(split: pd.DataFrame, mapper: dict) -> Dataset:\n",
    "    \"\"\"\n",
    "    Converts a pandas dataframe into a Dataset object\n",
    "    keeps only a handful of the columns I care about\n",
    "    \"\"\"\n",
    "    \n",
    "    names = list(mapper.keys())\n",
    "    ds = Dataset.from_pandas(\n",
    "        df = split[['english_name', 'description', 'labels']],\n",
    "        features = Features({\n",
    "            \"english_name\": Value(dtype=\"string\"),\n",
    "            \"description\": Value(dtype=\"string\"),\n",
    "            'labels': Sequence(\n",
    "                feature=Value(dtype=\"float32\"),\n",
    "                length=len(names)\n",
    "            ),\n",
    "            \"__index_level_0__\": Value(dtype=\"int64\")\n",
    "        })\n",
    "    )\n",
    "\n",
    "    return ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fab3eb65-af9a-4b4c-a429-03e49b57233b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['english_name', 'description', 'labels', '__index_level_0__'],\n",
       "        num_rows: 628\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['english_name', 'description', 'labels', '__index_level_0__'],\n",
       "        num_rows: 135\n",
       "    })\n",
       "    val: Dataset({\n",
       "        features: ['english_name', 'description', 'labels', '__index_level_0__'],\n",
       "        num_rows: 135\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds = DatasetDict({\n",
    "    \"train\": create_dataset(train, label2id),\n",
    "    \"test\": create_dataset(test, label2id),\n",
    "    \"val\": create_dataset(val, label2id)\n",
    "})\n",
    "\n",
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c94de003-ee30-4cec-aef5-9fc6de2d418d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'english_name': 'Wartortle',\n",
       " 'description': 'It is recognized as a symbol of longevity. If its shell has algae on it, that Wartortle is very old.',\n",
       " 'labels': [0.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0],\n",
       " '__index_level_0__': 7}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Exampe row\n",
    "ds[\"train\"][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9863167-7390-438c-8178-ca495ce460a9",
   "metadata": {},
   "source": [
    "## Tokenize Pokedex Description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1649eb69-4768-4e4d-9806-0c067fa79d83",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b16f1be418514452bc46c7535cc3a232",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/628 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3af43d638e0b4063a522039b19002ddc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/135 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f205af918dd44c098bdf40d4a18e5acd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/135 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_name = \"distilbert-base-uncased\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "def tokenize_description(example):\n",
    "    tokenized_desc = tokenizer(example['description'], padding='max_length', is_split_into_words=False, max_length=60)\n",
    "\n",
    "    return tokenized_desc\n",
    "\n",
    "ds = ds.map(\n",
    "    lambda example: tokenize_description(example)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "35fe7c2a-6a9e-4c1e-8c09-72de95822b7a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['english_name', 'description', 'labels', '__index_level_0__', 'input_ids', 'attention_mask'],\n",
       "    num_rows: 628\n",
       "})"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Take note of the new features\n",
    "ds[\"train\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce84cfe4-1846-438b-a7b6-564307c14588",
   "metadata": {},
   "source": [
    "### Verify tokenizer worked as intended"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "98715f31-3593-4e8a-80be-a96f98f1e79b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "it is recognized as a symbol of longevity. if its shell has algae on it, that wartortle is very old.\n",
      "It is recognized as a symbol of longevity. If its shell has algae on it, that Wartortle is very old.\n"
     ]
    }
   ],
   "source": [
    "first_row = ds[\"train\"][0]\n",
    "print(tokenizer.decode(first_row[\"input_ids\"], skip_special_tokens=True))\n",
    "print(first_row[\"description\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62c09f4b-1268-4d32-b665-3eb10f3c8130",
   "metadata": {},
   "source": [
    "### Verify equality of lengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "23512b70-aefd-4d72-8cf2-4b85416f70d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input IDs Length: 60\n",
      "Attention Mask Length: 60\n",
      "\n",
      "Input IDs Length: 60\n",
      "Attention Mask Length: 60\n",
      "\n",
      "Input IDs Length: 60\n",
      "Attention Mask Length: 60\n",
      "\n",
      "Input IDs Length: 60\n",
      "Attention Mask Length: 60\n",
      "\n",
      "Input IDs Length: 60\n",
      "Attention Mask Length: 60\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "60"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for index, example in enumerate(ds['train']):\n",
    "    if index < 5:\n",
    "        input_ids_length = len(example['input_ids'])\n",
    "        attention_mask_length = len(example['attention_mask'])\n",
    "        \n",
    "        # Print the lengths for each feature in this row\n",
    "        print(f'Input IDs Length: {input_ids_length}')\n",
    "        print(f'Attention Mask Length: {attention_mask_length}\\n')\n",
    "\n",
    "lengths = [len(row[\"input_ids\"]) for row in ds[\"train\"]]\n",
    "max(lengths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f80db095-c497-4d4a-817d-af2dedae4ac3",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds.set_format(\"torch\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9eda8b00-9c05-4b18-8516-03fc33a09948",
   "metadata": {},
   "source": [
    "# Building the Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "75c9b947-188e-426c-8f02-7d2bd9273ed9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import (\n",
    "    DataCollator, AutoModelForSequenceClassification, TrainingArguments, Trainer\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aad3a48a-b689-4a41-9ac3-58c1921e7be9",
   "metadata": {},
   "source": [
    "Below is code modified from [this notebook](https://github.com/NielsRogge/Transformers-Tutorials/blob/master/BERT/Fine_tuning_BERT_(and_friends)_for_multi_label_text_classification.ipynb). I had to tweak stuff like changing sigmoid to softmax and adding in my own custom function for extracting the top 2 predictions. Many examples utilize a threshold but due to the large number of classes I feel like that's not a good fit for this model. \n",
    "\n",
    "Gonna be honest here, mostly taking these metrics at face-value. Stuff gets weird in multi-label models and I had a lot of trouble figuring this out on my own. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "71638b2b-ba89-4b05-a8fa-b53a64c70af8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score, roc_auc_score, accuracy_score\n",
    "from transformers import EvalPrediction\n",
    "import torch\n",
    "from torch.nn.functional import softmax\n",
    "from torch import tensor, topk\n",
    "\n",
    "# source: https://jesusleal.io/2021/04/21/Longformer-multilabel-classification/\n",
    "def multi_label_metrics(predictions, labels, threshold=0.5):\n",
    "    # first, apply softmax to our logits to get our probabilities\n",
    "    probs = softmax(torch.Tensor(predictions))\n",
    "\n",
    "    def tensor_to_indices(tensor):\n",
    "        # Here this function takes a tensor of probabilities and returns the indices of the two highest probs\n",
    "        _, indices = topk(tensor, 2)\n",
    "        indices = indices.tolist()\n",
    "    \n",
    "        return sorted(indices)\n",
    "    \n",
    "    # next, use said indices to turn them into integer predictions\n",
    "    y_pred = np.zeros(probs.shape)\n",
    "    pred_indices = tensor_to_indices(probs)\n",
    "    for index, row in enumerate(y_pred):\n",
    "        row[pred_indices[index]] = 1\n",
    "    \n",
    "    # finally, compute metrics\n",
    "    y_true = labels\n",
    "    f1_micro_average = f1_score(y_true=y_true, y_pred=y_pred, average='micro')\n",
    "    roc_auc = roc_auc_score(y_true, y_pred, average = 'micro')\n",
    "    accuracy = accuracy_score(y_true, y_pred)\n",
    "    # return as dictionary\n",
    "    metrics = {'f1': f1_micro_average,\n",
    "               'roc_auc': roc_auc,\n",
    "               'accuracy': accuracy}\n",
    "    return metrics\n",
    "\n",
    "\n",
    "def compute_metrics(p: EvalPrediction):\n",
    "    preds = p.predictions[0] if isinstance(p.predictions, \n",
    "            tuple) else p.predictions\n",
    "    result = multi_label_metrics(\n",
    "        predictions=preds, \n",
    "        labels=p.label_ids)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "fb7a01d3-804c-425b-bb3f-0889acdafd19",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['pre_classifier.bias', 'classifier.weight', 'classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DistilBertForSequenceClassification(\n",
       "  (distilbert): DistilBertModel(\n",
       "    (embeddings): Embeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (transformer): Transformer(\n",
       "      (layer): ModuleList(\n",
       "        (0-5): 6 x TransformerBlock(\n",
       "          (attention): MultiHeadSelfAttention(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (ffn): FFN(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (activation): GELUActivation()\n",
       "          )\n",
       "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (pre_classifier): Linear(in_features=768, out_features=768, bias=True)\n",
       "  (classifier): Linear(in_features=768, out_features=19, bias=True)\n",
       "  (dropout): Dropout(p=0.2, inplace=False)\n",
       ")"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_labels = len(label2id.keys())\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    model_name, num_labels=len(names), problem_type=\"multi_label_classification\", id2label=id2label, label2id=label2id\n",
    ")\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "490ede12-8f5a-4b00-9f3b-ded4bc8c96c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_arguments = TrainingArguments(\n",
    "    output_dir=\"models\",\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=16,\n",
    "    num_train_epochs=10,\n",
    "    weight_decay=0.1,\n",
    "    logging_strategy=\"epoch\",\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    remove_unused_columns=False,\n",
    "    load_best_model_at_end=True\n",
    ")\n",
    "\n",
    "cols_to_train_on = [\"input_ids\", \"attention_mask\", \"labels\"]\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_arguments,\n",
    "    train_dataset=ds[\"train\"].select_columns(cols_to_train_on),\n",
    "    eval_dataset=ds[\"val\"].select_columns(cols_to_train_on),\n",
    "    compute_metrics=compute_metrics,\n",
    "    tokenizer=tokenizer\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "d1288464-74a1-4cd4-89c1-70d114eb43c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='400' max='400' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [400/400 02:51, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>F1</th>\n",
       "      <th>Roc Auc</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.165900</td>\n",
       "      <td>0.269975</td>\n",
       "      <td>0.211503</td>\n",
       "      <td>0.559563</td>\n",
       "      <td>0.029630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.149200</td>\n",
       "      <td>0.267790</td>\n",
       "      <td>0.267161</td>\n",
       "      <td>0.590711</td>\n",
       "      <td>0.059259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.137500</td>\n",
       "      <td>0.268863</td>\n",
       "      <td>0.252319</td>\n",
       "      <td>0.582405</td>\n",
       "      <td>0.051852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.131900</td>\n",
       "      <td>0.271124</td>\n",
       "      <td>0.252319</td>\n",
       "      <td>0.582405</td>\n",
       "      <td>0.044444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.123100</td>\n",
       "      <td>0.272594</td>\n",
       "      <td>0.233766</td>\n",
       "      <td>0.572022</td>\n",
       "      <td>0.037037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.114100</td>\n",
       "      <td>0.276763</td>\n",
       "      <td>0.244898</td>\n",
       "      <td>0.578251</td>\n",
       "      <td>0.044444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.107900</td>\n",
       "      <td>0.279984</td>\n",
       "      <td>0.263451</td>\n",
       "      <td>0.588634</td>\n",
       "      <td>0.059259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.103900</td>\n",
       "      <td>0.278569</td>\n",
       "      <td>0.270872</td>\n",
       "      <td>0.592787</td>\n",
       "      <td>0.066667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.100300</td>\n",
       "      <td>0.279651</td>\n",
       "      <td>0.241187</td>\n",
       "      <td>0.576175</td>\n",
       "      <td>0.044444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.097800</td>\n",
       "      <td>0.282006</td>\n",
       "      <td>0.244898</td>\n",
       "      <td>0.578251</td>\n",
       "      <td>0.037037</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WOOOOO -----\n",
      "tensor([[0.0345, 0.0159, 0.4387,  ..., 0.0185, 0.0384, 0.0385],\n",
      "        [0.0682, 0.0367, 0.0263,  ..., 0.0094, 0.0447, 0.0099],\n",
      "        [0.0317, 0.5222, 0.0031,  ..., 0.0071, 0.0362, 0.0030],\n",
      "        ...,\n",
      "        [0.0280, 0.3116, 0.0167,  ..., 0.0096, 0.0593, 0.0139],\n",
      "        [0.0267, 0.1262, 0.1946,  ..., 0.0119, 0.0357, 0.1758],\n",
      "        [0.0736, 0.3607, 0.0106,  ..., 0.0513, 0.0229, 0.0111]])\n",
      "[[0, 8], [0, 8], [0, 8], [1, 0], [1, 2], [1, 2], [1, 3], [1, 3], [1, 4], [1, 4], [1, 4], [1, 4], [1, 4], [1, 4], [1, 6], [1, 6], [1, 6], [1, 7], [1, 8], [1, 8], [1, 8], [1, 8], [1, 8], [1, 8], [1, 8], [1, 8], [1, 8], [1, 8], [1, 8], [1, 8], [1, 9], [1, 9], [1, 10], [1, 10], [1, 10], [1, 10], [1, 10], [1, 10], [1, 10], [1, 10], [1, 10], [1, 10], [1, 10], [1, 11], [1, 12], [1, 12], [1, 12], [1, 14], [1, 14], [1, 14], [1, 14], [1, 14], [1, 14], [1, 14], [1, 14], [1, 14], [1, 18], [1, 18], [1, 18], [1, 18], [1, 18], [1, 18], [1, 18], [1, 18], [1, 18], [1, 18], [1, 18], [1, 18], [1, 18], [1, 18], [1, 18], [1, 18], [2, 1], [2, 1], [2, 1], [2, 1], [2, 1], [2, 3], [2, 8], [2, 8], [2, 14], [2, 14], [2, 17], [2, 18], [2, 18], [2, 18], [2, 18], [2, 18], [2, 18], [2, 18], [3, 8], [4, 1], [6, 1], [8, 0], [8, 0], [8, 0], [8, 1], [8, 1], [8, 17], [9, 1], [9, 1], [10, 0], [10, 1], [10, 1], [10, 1], [10, 1], [10, 1], [10, 1], [10, 8], [10, 12], [10, 16], [10, 16], [10, 16], [10, 16], [10, 16], [10, 16], [10, 16], [12, 0], [12, 2], [12, 8], [12, 15], [12, 16], [13, 1], [13, 11], [14, 0], [14, 1], [14, 1], [14, 1], [14, 13], [14, 13], [14, 17], [17, 2], [17, 8], [17, 11], [18, 2]]\n",
      "[[1. 0. 0. ... 0. 0. 0.]\n",
      " [1. 0. 0. ... 0. 0. 0.]\n",
      " [1. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 1. 0.]\n",
      " [0. 0. 0. ... 0. 1. 0.]\n",
      " [0. 0. 1. ... 0. 0. 1.]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/4h/0fpdxq710mn1y0_ftjc8s6m80000gn/T/ipykernel_3239/1402213626.py:10: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  probs = softmax(torch.Tensor(predictions))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WOOOOO -----\n",
      "tensor([[0.0221, 0.0259, 0.2714,  ..., 0.0134, 0.0267, 0.0365],\n",
      "        [0.0154, 0.0404, 0.0099,  ..., 0.0033, 0.0138, 0.0071],\n",
      "        [0.0100, 0.3751, 0.0019,  ..., 0.0033, 0.0141, 0.0025],\n",
      "        ...,\n",
      "        [0.0103, 0.5907, 0.0073,  ..., 0.0041, 0.0385, 0.0100],\n",
      "        [0.0153, 0.2264, 0.0997,  ..., 0.0071, 0.0267, 0.1659],\n",
      "        [0.0126, 0.6907, 0.0020,  ..., 0.0090, 0.0069, 0.0052]])\n",
      "[[0, 1], [0, 14], [1, 2], [1, 2], [1, 2], [1, 4], [1, 4], [1, 4], [1, 4], [1, 4], [1, 4], [1, 4], [1, 5], [1, 6], [1, 6], [1, 6], [1, 8], [1, 8], [1, 8], [1, 8], [1, 8], [1, 8], [1, 9], [1, 9], [1, 10], [1, 10], [1, 10], [1, 10], [1, 10], [1, 10], [1, 10], [1, 10], [1, 10], [1, 11], [1, 13], [1, 14], [1, 14], [1, 14], [1, 14], [1, 14], [1, 14], [1, 14], [1, 14], [1, 14], [1, 14], [1, 14], [1, 14], [1, 14], [1, 14], [1, 14], [1, 14], [1, 14], [1, 14], [1, 14], [1, 14], [1, 14], [1, 14], [1, 14], [1, 14], [1, 14], [1, 14], [1, 14], [1, 14], [1, 17], [1, 18], [1, 18], [1, 18], [1, 18], [1, 18], [1, 18], [1, 18], [1, 18], [1, 18], [1, 18], [1, 18], [1, 18], [1, 18], [1, 18], [1, 18], [1, 18], [1, 18], [1, 18], [1, 18], [1, 18], [1, 18], [2, 1], [2, 1], [2, 14], [2, 17], [2, 18], [2, 18], [2, 18], [2, 18], [2, 18], [2, 18], [3, 2], [6, 13], [6, 14], [8, 0], [8, 1], [9, 1], [9, 15], [10, 1], [10, 1], [10, 1], [10, 1], [10, 1], [10, 1], [10, 3], [10, 6], [10, 16], [10, 16], [10, 16], [11, 10], [12, 0], [12, 1], [13, 5], [13, 11], [13, 11], [13, 14], [14, 1], [14, 1], [14, 1], [14, 1], [14, 1], [14, 1], [14, 1], [14, 1], [14, 2], [14, 13], [14, 17], [17, 2], [17, 8], [18, 1], [18, 2]]\n",
      "[[1. 1. 0. ... 0. 0. 0.]\n",
      " [1. 0. 0. ... 0. 0. 0.]\n",
      " [0. 1. 1. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 1. 0.]\n",
      " [0. 1. 0. ... 0. 0. 1.]\n",
      " [0. 0. 1. ... 0. 0. 1.]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/4h/0fpdxq710mn1y0_ftjc8s6m80000gn/T/ipykernel_3239/1402213626.py:10: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  probs = softmax(torch.Tensor(predictions))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WOOOOO -----\n",
      "tensor([[0.0241, 0.0179, 0.4606,  ..., 0.0144, 0.0226, 0.0439],\n",
      "        [0.0325, 0.0517, 0.0120,  ..., 0.0042, 0.0174, 0.0093],\n",
      "        [0.0107, 0.6329, 0.0013,  ..., 0.0031, 0.0147, 0.0017],\n",
      "        ...,\n",
      "        [0.0147, 0.5064, 0.0091,  ..., 0.0047, 0.0497, 0.0104],\n",
      "        [0.0181, 0.2602, 0.0946,  ..., 0.0073, 0.0215, 0.2199],\n",
      "        [0.0118, 0.8682, 0.0012,  ..., 0.0093, 0.0036, 0.0049]])\n",
      "[[0, 1], [0, 8], [1, 0], [1, 2], [1, 3], [1, 4], [1, 4], [1, 4], [1, 4], [1, 4], [1, 4], [1, 4], [1, 4], [1, 4], [1, 6], [1, 6], [1, 6], [1, 7], [1, 7], [1, 8], [1, 8], [1, 8], [1, 8], [1, 8], [1, 8], [1, 8], [1, 8], [1, 8], [1, 8], [1, 8], [1, 9], [1, 9], [1, 9], [1, 10], [1, 10], [1, 10], [1, 10], [1, 10], [1, 10], [1, 10], [1, 10], [1, 10], [1, 10], [1, 12], [1, 12], [1, 12], [1, 13], [1, 13], [1, 13], [1, 14], [1, 14], [1, 14], [1, 14], [1, 14], [1, 14], [1, 14], [1, 14], [1, 14], [1, 14], [1, 14], [1, 14], [1, 14], [1, 17], [1, 18], [1, 18], [1, 18], [1, 18], [1, 18], [1, 18], [1, 18], [1, 18], [1, 18], [1, 18], [1, 18], [1, 18], [1, 18], [1, 18], [1, 18], [1, 18], [1, 18], [1, 18], [1, 18], [1, 18], [1, 18], [1, 18], [1, 18], [1, 18], [1, 18], [1, 18], [1, 18], [1, 18], [2, 1], [2, 1], [2, 14], [2, 17], [2, 18], [2, 18], [2, 18], [2, 18], [2, 18], [3, 2], [3, 8], [6, 13], [8, 0], [8, 0], [8, 1], [8, 17], [8, 17], [9, 1], [9, 3], [10, 0], [10, 1], [10, 1], [10, 1], [10, 1], [10, 1], [10, 1], [10, 1], [10, 3], [10, 16], [10, 16], [10, 16], [12, 0], [12, 1], [13, 11], [13, 12], [13, 17], [14, 1], [14, 1], [14, 1], [14, 13], [16, 8], [17, 13], [18, 1], [18, 2]]\n",
      "[[1. 1. 0. ... 0. 0. 0.]\n",
      " [1. 0. 0. ... 0. 0. 0.]\n",
      " [1. 1. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 1. 0.]\n",
      " [0. 1. 0. ... 0. 0. 1.]\n",
      " [0. 0. 1. ... 0. 0. 1.]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/4h/0fpdxq710mn1y0_ftjc8s6m80000gn/T/ipykernel_3239/1402213626.py:10: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  probs = softmax(torch.Tensor(predictions))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WOOOOO -----\n",
      "tensor([[2.5240e-02, 2.4547e-02, 3.0166e-01,  ..., 1.4958e-02, 1.8843e-02,\n",
      "         3.9302e-02],\n",
      "        [2.1594e-02, 3.6881e-02, 3.8243e-03,  ..., 2.5235e-03, 1.0620e-02,\n",
      "         3.3865e-03],\n",
      "        [7.4693e-03, 6.2448e-01, 6.2874e-04,  ..., 2.0239e-03, 8.7271e-03,\n",
      "         1.0144e-03],\n",
      "        ...,\n",
      "        [1.3736e-02, 4.6127e-01, 5.7586e-03,  ..., 4.3051e-03, 4.8369e-02,\n",
      "         6.8296e-03],\n",
      "        [2.0470e-02, 2.7769e-01, 5.0803e-02,  ..., 7.3598e-03, 2.1330e-02,\n",
      "         1.4872e-01],\n",
      "        [2.3912e-02, 7.2967e-01, 9.9070e-04,  ..., 1.4658e-02, 4.9046e-03,\n",
      "         3.5821e-03]])\n",
      "[[0, 1], [0, 8], [0, 8], [1, 0], [1, 2], [1, 3], [1, 4], [1, 4], [1, 4], [1, 4], [1, 4], [1, 4], [1, 4], [1, 5], [1, 5], [1, 6], [1, 6], [1, 6], [1, 6], [1, 6], [1, 7], [1, 7], [1, 8], [1, 8], [1, 8], [1, 8], [1, 8], [1, 8], [1, 8], [1, 8], [1, 8], [1, 8], [1, 8], [1, 8], [1, 9], [1, 9], [1, 9], [1, 10], [1, 10], [1, 10], [1, 10], [1, 10], [1, 10], [1, 10], [1, 10], [1, 11], [1, 12], [1, 12], [1, 13], [1, 13], [1, 14], [1, 14], [1, 14], [1, 14], [1, 14], [1, 14], [1, 14], [1, 14], [1, 14], [1, 14], [1, 14], [1, 14], [1, 14], [1, 14], [1, 14], [1, 14], [1, 14], [1, 14], [1, 14], [1, 14], [1, 14], [1, 14], [1, 17], [1, 18], [1, 18], [1, 18], [1, 18], [1, 18], [1, 18], [1, 18], [1, 18], [1, 18], [1, 18], [1, 18], [1, 18], [1, 18], [1, 18], [1, 18], [1, 18], [2, 14], [2, 14], [2, 17], [2, 18], [2, 18], [2, 18], [2, 18], [3, 8], [3, 8], [3, 10], [4, 1], [6, 0], [6, 13], [8, 0], [8, 0], [8, 1], [8, 1], [8, 16], [8, 17], [8, 17], [9, 1], [9, 3], [10, 1], [10, 1], [10, 1], [10, 1], [10, 1], [10, 6], [10, 16], [12, 0], [12, 1], [13, 1], [13, 1], [13, 5], [13, 11], [13, 12], [14, 1], [14, 1], [14, 1], [14, 1], [14, 1], [14, 13], [16, 8], [16, 10], [18, 1], [18, 2]]\n",
      "[[1. 1. 0. ... 0. 0. 0.]\n",
      " [1. 0. 0. ... 0. 0. 0.]\n",
      " [1. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 1. 0. 0.]\n",
      " [0. 1. 0. ... 0. 0. 1.]\n",
      " [0. 0. 1. ... 0. 0. 1.]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/4h/0fpdxq710mn1y0_ftjc8s6m80000gn/T/ipykernel_3239/1402213626.py:10: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  probs = softmax(torch.Tensor(predictions))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WOOOOO -----\n",
      "tensor([[2.0763e-02, 1.3582e-02, 4.4781e-01,  ..., 1.2231e-02, 1.5822e-02,\n",
      "         4.5300e-02],\n",
      "        [1.9988e-02, 4.1928e-02, 6.2873e-03,  ..., 2.2963e-03, 1.0065e-02,\n",
      "         6.3019e-03],\n",
      "        [4.2946e-03, 7.4269e-01, 3.9157e-04,  ..., 1.0532e-03, 5.4863e-03,\n",
      "         7.8093e-04],\n",
      "        ...,\n",
      "        [6.9822e-03, 6.5195e-01, 4.2548e-03,  ..., 2.2844e-03, 2.7320e-02,\n",
      "         7.6285e-03],\n",
      "        [1.6852e-02, 2.3673e-01, 7.4075e-02,  ..., 6.3528e-03, 1.6912e-02,\n",
      "         2.2978e-01],\n",
      "        [1.0621e-02, 8.6865e-01, 5.8674e-04,  ..., 9.0501e-03, 2.2443e-03,\n",
      "         2.8467e-03]])\n",
      "[[0, 1], [0, 8], [0, 17], [1, 0], [1, 0], [1, 0], [1, 2], [1, 2], [1, 2], [1, 4], [1, 4], [1, 4], [1, 4], [1, 4], [1, 4], [1, 4], [1, 4], [1, 6], [1, 6], [1, 6], [1, 7], [1, 7], [1, 7], [1, 8], [1, 8], [1, 8], [1, 8], [1, 8], [1, 8], [1, 8], [1, 8], [1, 9], [1, 9], [1, 9], [1, 10], [1, 10], [1, 10], [1, 10], [1, 10], [1, 10], [1, 10], [1, 10], [1, 10], [1, 10], [1, 11], [1, 12], [1, 12], [1, 13], [1, 13], [1, 13], [1, 14], [1, 14], [1, 14], [1, 14], [1, 14], [1, 14], [1, 14], [1, 14], [1, 14], [1, 14], [1, 14], [1, 14], [1, 14], [1, 14], [1, 14], [1, 14], [1, 14], [1, 17], [1, 18], [1, 18], [1, 18], [1, 18], [1, 18], [1, 18], [1, 18], [1, 18], [1, 18], [1, 18], [1, 18], [1, 18], [1, 18], [1, 18], [1, 18], [1, 18], [1, 18], [1, 18], [1, 18], [1, 18], [1, 18], [1, 18], [1, 18], [2, 1], [2, 14], [2, 17], [2, 18], [2, 18], [2, 18], [2, 18], [2, 18], [2, 18], [3, 10], [3, 15], [6, 13], [8, 0], [8, 1], [8, 3], [8, 17], [9, 1], [9, 3], [10, 0], [10, 1], [10, 1], [10, 1], [10, 1], [10, 1], [10, 1], [10, 1], [10, 8], [10, 16], [10, 16], [12, 0], [12, 1], [13, 4], [13, 11], [13, 11], [13, 11], [14, 1], [14, 1], [14, 1], [14, 1], [14, 1], [14, 13], [16, 10], [17, 8], [18, 3]]\n",
      "[[1. 1. 0. ... 0. 0. 0.]\n",
      " [1. 0. 0. ... 0. 0. 0.]\n",
      " [1. 0. 0. ... 0. 1. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 1. 0. 0.]\n",
      " [0. 0. 0. ... 0. 1. 0.]\n",
      " [0. 0. 0. ... 0. 0. 1.]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/4h/0fpdxq710mn1y0_ftjc8s6m80000gn/T/ipykernel_3239/1402213626.py:10: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  probs = softmax(torch.Tensor(predictions))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WOOOOO -----\n",
      "tensor([[2.5431e-02, 2.1328e-02, 3.2579e-01,  ..., 1.6165e-02, 1.2807e-02,\n",
      "         4.2732e-02],\n",
      "        [2.3765e-02, 7.0263e-02, 2.7846e-03,  ..., 2.2505e-03, 7.0133e-03,\n",
      "         4.4207e-03],\n",
      "        [3.5312e-03, 8.7157e-01, 2.2979e-04,  ..., 8.5105e-04, 3.9201e-03,\n",
      "         4.9250e-04],\n",
      "        ...,\n",
      "        [6.8491e-03, 5.9550e-01, 3.1415e-03,  ..., 2.2123e-03, 2.3508e-02,\n",
      "         5.4354e-03],\n",
      "        [1.6147e-02, 4.3093e-01, 2.9454e-02,  ..., 5.7809e-03, 9.5838e-03,\n",
      "         1.7313e-01],\n",
      "        [9.7396e-03, 8.8490e-01, 4.3095e-04,  ..., 9.2850e-03, 1.5674e-03,\n",
      "         2.5110e-03]])\n",
      "[[0, 1], [0, 8], [0, 8], [1, 0], [1, 2], [1, 2], [1, 3], [1, 4], [1, 4], [1, 4], [1, 4], [1, 4], [1, 4], [1, 4], [1, 6], [1, 6], [1, 6], [1, 6], [1, 6], [1, 7], [1, 7], [1, 7], [1, 7], [1, 8], [1, 8], [1, 8], [1, 8], [1, 8], [1, 8], [1, 8], [1, 8], [1, 8], [1, 8], [1, 8], [1, 8], [1, 8], [1, 8], [1, 9], [1, 9], [1, 9], [1, 9], [1, 10], [1, 10], [1, 10], [1, 10], [1, 10], [1, 10], [1, 10], [1, 10], [1, 10], [1, 10], [1, 10], [1, 10], [1, 10], [1, 11], [1, 12], [1, 12], [1, 12], [1, 13], [1, 13], [1, 14], [1, 14], [1, 14], [1, 14], [1, 14], [1, 14], [1, 14], [1, 14], [1, 14], [1, 14], [1, 14], [1, 14], [1, 14], [1, 14], [1, 18], [1, 18], [1, 18], [1, 18], [1, 18], [1, 18], [1, 18], [1, 18], [1, 18], [1, 18], [1, 18], [1, 18], [1, 18], [1, 18], [1, 18], [1, 18], [1, 18], [1, 18], [1, 18], [1, 18], [1, 18], [1, 18], [2, 14], [2, 17], [2, 18], [2, 18], [2, 18], [2, 18], [2, 18], [3, 8], [3, 9], [4, 13], [6, 1], [8, 0], [8, 1], [8, 3], [8, 17], [8, 17], [10, 0], [10, 1], [10, 1], [10, 1], [10, 1], [10, 1], [10, 1], [10, 3], [10, 8], [10, 16], [10, 16], [12, 0], [12, 1], [12, 13], [13, 1], [13, 11], [14, 1], [14, 1], [14, 1], [14, 13], [16, 10], [18, 1], [18, 2]]\n",
      "[[1. 1. 0. ... 0. 0. 0.]\n",
      " [1. 0. 0. ... 0. 0. 0.]\n",
      " [1. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 1. 0. 0.]\n",
      " [0. 1. 0. ... 0. 0. 1.]\n",
      " [0. 0. 1. ... 0. 0. 1.]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/4h/0fpdxq710mn1y0_ftjc8s6m80000gn/T/ipykernel_3239/1402213626.py:10: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  probs = softmax(torch.Tensor(predictions))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WOOOOO -----\n",
      "tensor([[2.0062e-02, 2.5252e-02, 2.4382e-01,  ..., 1.2616e-02, 1.2432e-02,\n",
      "         2.8876e-02],\n",
      "        [1.4558e-02, 3.3585e-02, 2.2823e-03,  ..., 1.5373e-03, 6.3287e-03,\n",
      "         2.1168e-03],\n",
      "        [2.3379e-03, 8.3908e-01, 2.1540e-04,  ..., 7.0387e-04, 3.4231e-03,\n",
      "         4.2053e-04],\n",
      "        ...,\n",
      "        [5.0951e-03, 7.2086e-01, 2.4376e-03,  ..., 1.7149e-03, 2.7081e-02,\n",
      "         3.3581e-03],\n",
      "        [1.5989e-02, 4.0206e-01, 3.1882e-02,  ..., 5.2081e-03, 1.4409e-02,\n",
      "         1.1711e-01],\n",
      "        [7.0865e-03, 8.7094e-01, 2.8643e-04,  ..., 6.3925e-03, 1.9132e-03,\n",
      "         1.0855e-03]])\n",
      "[[0, 1], [0, 8], [0, 17], [1, 0], [1, 0], [1, 2], [1, 2], [1, 2], [1, 3], [1, 3], [1, 4], [1, 4], [1, 4], [1, 4], [1, 4], [1, 4], [1, 4], [1, 4], [1, 5], [1, 5], [1, 6], [1, 6], [1, 6], [1, 6], [1, 6], [1, 7], [1, 7], [1, 7], [1, 8], [1, 8], [1, 8], [1, 8], [1, 8], [1, 8], [1, 8], [1, 8], [1, 8], [1, 9], [1, 9], [1, 9], [1, 10], [1, 10], [1, 10], [1, 10], [1, 10], [1, 10], [1, 10], [1, 10], [1, 10], [1, 10], [1, 11], [1, 12], [1, 12], [1, 13], [1, 13], [1, 13], [1, 13], [1, 14], [1, 14], [1, 14], [1, 14], [1, 14], [1, 14], [1, 14], [1, 14], [1, 14], [1, 14], [1, 14], [1, 14], [1, 14], [1, 14], [1, 14], [1, 14], [1, 14], [1, 14], [1, 14], [1, 14], [1, 17], [1, 17], [1, 18], [1, 18], [1, 18], [1, 18], [1, 18], [1, 18], [1, 18], [1, 18], [1, 18], [1, 18], [1, 18], [1, 18], [1, 18], [1, 18], [1, 18], [1, 18], [2, 14], [2, 17], [2, 18], [2, 18], [2, 18], [2, 18], [3, 1], [3, 8], [3, 10], [6, 0], [6, 1], [8, 0], [8, 0], [8, 1], [8, 3], [8, 17], [9, 1], [9, 3], [10, 1], [10, 1], [10, 1], [10, 1], [10, 1], [10, 16], [12, 0], [12, 1], [13, 11], [13, 12], [13, 17], [14, 1], [14, 1], [14, 1], [14, 1], [14, 2], [14, 13], [16, 8], [16, 10], [16, 10], [17, 14], [18, 2]]\n",
      "[[1. 1. 0. ... 0. 0. 0.]\n",
      " [1. 0. 0. ... 0. 0. 0.]\n",
      " [1. 0. 0. ... 0. 1. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 1. 0. 0.]\n",
      " [0. 0. 0. ... 0. 1. 0.]\n",
      " [0. 0. 1. ... 0. 0. 1.]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/4h/0fpdxq710mn1y0_ftjc8s6m80000gn/T/ipykernel_3239/1402213626.py:10: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  probs = softmax(torch.Tensor(predictions))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WOOOOO -----\n",
      "tensor([[1.8947e-02, 2.1494e-02, 3.0739e-01,  ..., 1.1300e-02, 9.5443e-03,\n",
      "         4.4381e-02],\n",
      "        [1.4089e-02, 3.0203e-02, 2.5458e-03,  ..., 1.4294e-03, 5.1985e-03,\n",
      "         2.8772e-03],\n",
      "        [1.7946e-03, 8.5959e-01, 1.6597e-04,  ..., 5.1501e-04, 2.3536e-03,\n",
      "         4.3511e-04],\n",
      "        ...,\n",
      "        [4.4431e-03, 7.4887e-01, 2.2557e-03,  ..., 1.3481e-03, 2.1100e-02,\n",
      "         4.0723e-03],\n",
      "        [1.3395e-02, 3.5014e-01, 3.9321e-02,  ..., 4.6254e-03, 8.8922e-03,\n",
      "         2.2077e-01],\n",
      "        [3.9335e-03, 9.1509e-01, 2.3439e-04,  ..., 3.9714e-03, 1.0752e-03,\n",
      "         1.6417e-03]])\n",
      "[[0, 1], [0, 6], [0, 8], [0, 17], [1, 0], [1, 2], [1, 2], [1, 2], [1, 3], [1, 4], [1, 4], [1, 4], [1, 4], [1, 4], [1, 4], [1, 4], [1, 4], [1, 5], [1, 6], [1, 6], [1, 6], [1, 6], [1, 7], [1, 7], [1, 7], [1, 8], [1, 8], [1, 8], [1, 8], [1, 8], [1, 8], [1, 8], [1, 8], [1, 9], [1, 9], [1, 9], [1, 10], [1, 10], [1, 10], [1, 10], [1, 10], [1, 10], [1, 10], [1, 10], [1, 10], [1, 10], [1, 10], [1, 11], [1, 12], [1, 12], [1, 13], [1, 13], [1, 14], [1, 14], [1, 14], [1, 14], [1, 14], [1, 14], [1, 14], [1, 14], [1, 14], [1, 14], [1, 14], [1, 14], [1, 14], [1, 14], [1, 14], [1, 14], [1, 14], [1, 14], [1, 14], [1, 14], [1, 17], [1, 18], [1, 18], [1, 18], [1, 18], [1, 18], [1, 18], [1, 18], [1, 18], [1, 18], [1, 18], [1, 18], [1, 18], [1, 18], [1, 18], [1, 18], [1, 18], [1, 18], [1, 18], [1, 18], [1, 18], [1, 18], [1, 18], [1, 18], [1, 18], [2, 17], [2, 18], [2, 18], [2, 18], [2, 18], [2, 18], [3, 8], [3, 10], [3, 15], [6, 13], [8, 0], [8, 1], [8, 17], [9, 1], [9, 3], [10, 1], [10, 1], [10, 1], [10, 1], [10, 16], [10, 16], [12, 0], [12, 1], [13, 1], [13, 11], [13, 11], [13, 17], [14, 1], [14, 1], [14, 1], [14, 1], [14, 2], [14, 13], [16, 10], [16, 10], [17, 14], [18, 1], [18, 2]]\n",
      "[[1. 1. 0. ... 0. 0. 0.]\n",
      " [1. 0. 0. ... 0. 0. 0.]\n",
      " [1. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 1. 0.]\n",
      " [0. 1. 0. ... 0. 0. 1.]\n",
      " [0. 0. 1. ... 0. 0. 1.]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/4h/0fpdxq710mn1y0_ftjc8s6m80000gn/T/ipykernel_3239/1402213626.py:10: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  probs = softmax(torch.Tensor(predictions))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WOOOOO -----\n",
      "tensor([[1.8704e-02, 1.9626e-02, 2.6497e-01,  ..., 1.3109e-02, 9.9849e-03,\n",
      "         3.2812e-02],\n",
      "        [1.2269e-02, 2.2652e-02, 1.9150e-03,  ..., 1.3335e-03, 4.9737e-03,\n",
      "         1.8249e-03],\n",
      "        [2.0349e-03, 8.4145e-01, 1.7579e-04,  ..., 6.6797e-04, 2.7862e-03,\n",
      "         3.8491e-04],\n",
      "        ...,\n",
      "        [4.7168e-03, 7.0603e-01, 2.2381e-03,  ..., 1.6261e-03, 2.6719e-02,\n",
      "         3.2898e-03],\n",
      "        [1.4189e-02, 3.5915e-01, 3.5001e-02,  ..., 5.1912e-03, 9.6885e-03,\n",
      "         1.8843e-01],\n",
      "        [3.7227e-03, 9.2297e-01, 1.9348e-04,  ..., 4.9731e-03, 1.1536e-03,\n",
      "         1.0588e-03]])\n",
      "[[0, 1], [0, 8], [0, 17], [1, 0], [1, 0], [1, 0], [1, 2], [1, 2], [1, 4], [1, 4], [1, 4], [1, 4], [1, 4], [1, 4], [1, 4], [1, 5], [1, 6], [1, 6], [1, 6], [1, 6], [1, 6], [1, 7], [1, 7], [1, 7], [1, 8], [1, 8], [1, 8], [1, 8], [1, 8], [1, 8], [1, 8], [1, 8], [1, 9], [1, 9], [1, 9], [1, 10], [1, 10], [1, 10], [1, 10], [1, 10], [1, 10], [1, 10], [1, 10], [1, 10], [1, 10], [1, 10], [1, 10], [1, 11], [1, 12], [1, 12], [1, 13], [1, 13], [1, 14], [1, 14], [1, 14], [1, 14], [1, 14], [1, 14], [1, 14], [1, 14], [1, 14], [1, 14], [1, 14], [1, 14], [1, 14], [1, 14], [1, 14], [1, 14], [1, 14], [1, 14], [1, 15], [1, 17], [1, 18], [1, 18], [1, 18], [1, 18], [1, 18], [1, 18], [1, 18], [1, 18], [1, 18], [1, 18], [1, 18], [1, 18], [1, 18], [1, 18], [1, 18], [1, 18], [1, 18], [1, 18], [1, 18], [1, 18], [1, 18], [1, 18], [1, 18], [2, 17], [2, 18], [2, 18], [2, 18], [2, 18], [2, 18], [3, 10], [3, 15], [6, 10], [6, 13], [8, 0], [8, 1], [8, 3], [8, 17], [9, 1], [9, 3], [10, 1], [10, 1], [10, 1], [10, 1], [10, 1], [10, 1], [10, 16], [10, 16], [11, 12], [12, 0], [12, 1], [13, 1], [13, 11], [13, 17], [14, 1], [14, 1], [14, 1], [14, 2], [14, 9], [14, 13], [16, 10], [16, 10], [17, 14], [18, 2]]\n",
      "[[1. 1. 0. ... 0. 0. 0.]\n",
      " [1. 0. 0. ... 0. 0. 0.]\n",
      " [1. 0. 0. ... 0. 1. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 1. 0. 0.]\n",
      " [0. 0. 0. ... 0. 1. 0.]\n",
      " [0. 0. 1. ... 0. 0. 1.]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/4h/0fpdxq710mn1y0_ftjc8s6m80000gn/T/ipykernel_3239/1402213626.py:10: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  probs = softmax(torch.Tensor(predictions))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WOOOOO -----\n",
      "tensor([[1.8416e-02, 2.3541e-02, 3.1584e-01,  ..., 1.2036e-02, 9.6283e-03,\n",
      "         4.1337e-02],\n",
      "        [1.5202e-02, 4.0350e-02, 2.2235e-03,  ..., 1.3950e-03, 5.8749e-03,\n",
      "         2.6865e-03],\n",
      "        [1.3331e-03, 9.2172e-01, 1.1399e-04,  ..., 4.1046e-04, 1.8451e-03,\n",
      "         3.0296e-04],\n",
      "        ...,\n",
      "        [3.8073e-03, 7.3136e-01, 1.9318e-03,  ..., 1.2849e-03, 2.0539e-02,\n",
      "         3.4540e-03],\n",
      "        [1.2178e-02, 4.3186e-01, 2.9150e-02,  ..., 4.0981e-03, 7.7948e-03,\n",
      "         2.0184e-01],\n",
      "        [2.5750e-03, 9.5197e-01, 1.3867e-04,  ..., 3.3844e-03, 7.5887e-04,\n",
      "         9.4348e-04]])\n",
      "[[0, 1], [0, 8], [0, 17], [1, 0], [1, 0], [1, 0], [1, 2], [1, 2], [1, 4], [1, 4], [1, 4], [1, 4], [1, 4], [1, 4], [1, 4], [1, 6], [1, 6], [1, 6], [1, 6], [1, 6], [1, 7], [1, 7], [1, 7], [1, 7], [1, 8], [1, 8], [1, 8], [1, 8], [1, 8], [1, 8], [1, 8], [1, 8], [1, 9], [1, 9], [1, 9], [1, 9], [1, 10], [1, 10], [1, 10], [1, 10], [1, 10], [1, 10], [1, 10], [1, 10], [1, 10], [1, 10], [1, 10], [1, 10], [1, 10], [1, 11], [1, 12], [1, 12], [1, 12], [1, 13], [1, 13], [1, 14], [1, 14], [1, 14], [1, 14], [1, 14], [1, 14], [1, 14], [1, 14], [1, 14], [1, 14], [1, 14], [1, 14], [1, 14], [1, 14], [1, 14], [1, 14], [1, 15], [1, 17], [1, 18], [1, 18], [1, 18], [1, 18], [1, 18], [1, 18], [1, 18], [1, 18], [1, 18], [1, 18], [1, 18], [1, 18], [1, 18], [1, 18], [1, 18], [1, 18], [1, 18], [1, 18], [1, 18], [1, 18], [1, 18], [1, 18], [1, 18], [1, 18], [2, 14], [2, 17], [2, 18], [2, 18], [2, 18], [2, 18], [2, 18], [3, 10], [3, 15], [6, 13], [8, 0], [8, 1], [8, 3], [8, 17], [9, 1], [9, 3], [10, 1], [10, 1], [10, 1], [10, 1], [10, 1], [10, 6], [10, 16], [10, 16], [10, 16], [11, 12], [12, 0], [12, 1], [13, 1], [13, 11], [13, 17], [14, 1], [14, 1], [14, 1], [14, 13], [16, 10], [17, 8], [18, 2]]\n",
      "[[1. 1. 0. ... 0. 0. 0.]\n",
      " [1. 0. 0. ... 0. 0. 0.]\n",
      " [1. 0. 0. ... 0. 1. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 1. 0. 0.]\n",
      " [0. 0. 0. ... 0. 1. 0.]\n",
      " [0. 0. 1. ... 0. 0. 1.]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/4h/0fpdxq710mn1y0_ftjc8s6m80000gn/T/ipykernel_3239/1402213626.py:10: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  probs = softmax(torch.Tensor(predictions))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=400, training_loss=0.12316525280475617, metrics={'train_runtime': 171.577, 'train_samples_per_second': 36.602, 'train_steps_per_second': 2.331, 'total_flos': 97517281636800.0, 'train_loss': 0.12316525280475617, 'epoch': 10.0})"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "abff94ba-4067-4c42-91b5-46ee45213e35",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WOOOOO -----\n",
      "tensor([[9.0379e-03, 2.5823e-01, 5.4908e-03,  ..., 3.2145e-03, 8.1895e-03,\n",
      "         1.4389e-02],\n",
      "        [3.9041e-01, 2.6214e-02, 3.2358e-03,  ..., 7.4139e-03, 3.2413e-02,\n",
      "         8.6807e-04],\n",
      "        [7.5333e-05, 9.9686e-01, 2.8050e-05,  ..., 9.5401e-05, 1.0841e-04,\n",
      "         3.6687e-04],\n",
      "        ...,\n",
      "        [3.3390e-02, 2.7972e-01, 3.0716e-02,  ..., 5.3130e-02, 1.6841e-02,\n",
      "         3.8278e-02],\n",
      "        [4.6783e-04, 8.8663e-01, 1.2667e-03,  ..., 2.2241e-03, 1.4061e-03,\n",
      "         3.3956e-03],\n",
      "        [6.1318e-04, 9.3498e-01, 5.5742e-04,  ..., 1.2035e-03, 8.2783e-04,\n",
      "         3.6331e-03]])\n",
      "[[0, 3], [0, 14], [0, 17], [0, 17], [1, 0], [1, 0], [1, 0], [1, 0], [1, 3], [1, 3], [1, 3], [1, 4], [1, 4], [1, 4], [1, 4], [1, 5], [1, 5], [1, 6], [1, 6], [1, 6], [1, 7], [1, 7], [1, 7], [1, 8], [1, 8], [1, 8], [1, 8], [1, 8], [1, 8], [1, 8], [1, 8], [1, 8], [1, 9], [1, 9], [1, 9], [1, 9], [1, 9], [1, 9], [1, 9], [1, 10], [1, 10], [1, 10], [1, 10], [1, 10], [1, 10], [1, 10], [1, 10], [1, 11], [1, 12], [1, 12], [1, 12], [1, 12], [1, 12], [1, 13], [1, 14], [1, 14], [1, 14], [1, 14], [1, 14], [1, 14], [1, 14], [1, 14], [1, 14], [1, 14], [1, 14], [1, 14], [1, 14], [1, 14], [1, 14], [1, 14], [1, 17], [1, 18], [1, 18], [1, 18], [1, 18], [1, 18], [1, 18], [1, 18], [1, 18], [1, 18], [1, 18], [1, 18], [1, 18], [1, 18], [1, 18], [1, 18], [1, 18], [1, 18], [1, 18], [1, 18], [1, 18], [1, 18], [2, 8], [2, 14], [2, 18], [2, 18], [2, 18], [2, 18], [3, 9], [3, 15], [4, 1], [4, 1], [4, 1], [5, 1], [6, 1], [6, 1], [6, 13], [6, 13], [6, 16], [8, 0], [8, 0], [8, 1], [8, 1], [8, 1], [8, 17], [9, 1], [9, 1], [9, 15], [9, 16], [10, 1], [10, 1], [10, 1], [10, 16], [12, 1], [12, 1], [12, 2], [13, 2], [14, 1], [14, 1], [14, 1], [14, 1], [14, 1], [14, 17], [14, 17], [18, 1]]\n",
      "[[1. 0. 0. ... 0. 0. 0.]\n",
      " [1. 0. 0. ... 0. 0. 0.]\n",
      " [1. 0. 0. ... 0. 1. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 1. 0.]\n",
      " [0. 0. 0. ... 0. 1. 0.]\n",
      " [0. 1. 0. ... 0. 0. 1.]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/4h/0fpdxq710mn1y0_ftjc8s6m80000gn/T/ipykernel_3239/1402213626.py:10: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  probs = softmax(torch.Tensor(predictions))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "PredictionOutput(predictions=array([[-3.0452335 ,  0.30720177, -3.5435908 , ..., -4.0789914 ,\n",
       "        -3.1438055 , -2.5802224 ],\n",
       "       [ 0.5469722 , -2.1539192 , -4.2459393 , ..., -3.4168632 ,\n",
       "        -1.9416597 , -5.5616994 ],\n",
       "       [-4.7129016 ,  4.7775445 , -5.7008457 , ..., -4.4767337 ,\n",
       "        -4.3489485 , -3.1298065 ],\n",
       "       ...,\n",
       "       [-3.69219   , -1.5666349 , -3.7756586 , ..., -3.2276976 ,\n",
       "        -4.3766274 , -3.5555682 ],\n",
       "       [-5.1851215 ,  2.3619444 , -4.1890297 , ..., -3.626136  ,\n",
       "        -4.0846944 , -3.2029939 ],\n",
       "       [-4.6511045 ,  2.6785204 , -4.746437  , ..., -3.9767478 ,\n",
       "        -4.3509526 , -2.8719153 ]], dtype=float32), label_ids=array([[0., 1., 0., ..., 0., 0., 0.],\n",
       "       [1., 0., 0., ..., 0., 1., 0.],\n",
       "       [0., 1., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 1., 0., ..., 0., 0., 0.],\n",
       "       [0., 1., 0., ..., 0., 0., 1.]], dtype=float32), metrics={'test_loss': 0.2651369869709015, 'test_f1': 0.3, 'test_roc_auc': 0.6088235294117647, 'test_accuracy': 0.037037037037037035, 'test_runtime': 0.9667, 'test_samples_per_second': 139.649, 'test_steps_per_second': 9.31})"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.predict(ds[\"test\"].select_columns(cols_to_train_on))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
